PS D:\Users\jmuts\Documenten\school\jaar 4\Semester 7 Artificial intelligence\personal\code\pyImageSearch> & C:/Users/jmuts/AppData/Local/Programs/Python/Python310/python.exe "d:/Users/jmuts/Documenten/school/jaar 4/Semester 7 Artificial intelligence/personal/code/pyImageSearch/ocr-keras-tensorflow/train_ocr_model.py"
run started at: 2022-10-21 17:18:45
[INFO] loading datasets...
[INFO] datasets loaded.
started training session 0
[INFO] loading existing model...
2022-10-21 17:23:13.277854: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-21 17:23:13.865030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4626 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1
[INFO] training network...
training started at: 2022-10-21 17:23:14
Epoch 1/30
2022-10-21 17:23:18.703296: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500
4362/4362 [==============================] - ETA: 0s - loss: 1.9470 - accuracy: 0.81542022-10-21 17:31:10.023416: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 571748352 exceeds 10% of free system memory.
4362/4362 [==============================] - 546s 124ms/step - loss: 1.9470 - accuracy: 0.8154 - val_loss: 0.7660 - val_accuracy: 0.8243
Epoch 2/30
4362/4362 [==============================] - 543s 125ms/step - loss: 1.9442 - accuracy: 0.8169 - val_loss: 0.8640 - val_accuracy: 0.8195
Epoch 3/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9448 - accuracy: 0.8164 - val_loss: 0.7727 - val_accuracy: 0.8251
Epoch 4/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9467 - accuracy: 0.8160 - val_loss: 0.7914 - val_accuracy: 0.8263
Epoch 5/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9430 - accuracy: 0.8163 - val_loss: 0.7963 - val_accuracy: 0.8241
Epoch 6/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9412 - accuracy: 0.8168 - val_loss: 0.7789 - val_accuracy: 0.8228
Epoch 7/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9420 - accuracy: 0.8170 - val_loss: 0.8414 - val_accuracy: 0.8219
Epoch 8/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9421 - accuracy: 0.8171 - val_loss: 0.7733 - val_accuracy: 0.8218
Epoch 9/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9390 - accuracy: 0.8164 - val_loss: 0.7862 - val_accuracy: 0.8261
Epoch 10/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9372 - accuracy: 0.8172 - val_loss: 0.7834 - val_accuracy: 0.8209
Epoch 11/30
4362/4362 [==============================] - 546s 125ms/step - loss: 1.9377 - accuracy: 0.8167 - val_loss: 0.8078 - val_accuracy: 0.8265
Epoch 12/30
4362/4362 [==============================] - 542s 124ms/step - loss: 1.9393 - accuracy: 0.8159 - val_loss: 0.8108 - val_accuracy: 0.8234
Epoch 13/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9387 - accuracy: 0.8168 - val_loss: 0.7723 - val_accuracy: 0.8237
Epoch 14/30
4362/4362 [==============================] - 543s 124ms/step - loss: 1.9349 - accuracy: 0.8169 - val_loss: 0.7903 - val_accuracy: 0.8244
Epoch 15/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9375 - accuracy: 0.8170 - val_loss: 0.7732 - val_accuracy: 0.8229
Epoch 16/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9412 - accuracy: 0.8173 - val_loss: 0.7742 - val_accuracy: 0.8223
Epoch 17/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9369 - accuracy: 0.8168 - val_loss: 0.7755 - val_accuracy: 0.8222
Epoch 18/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9365 - accuracy: 0.8177 - val_loss: 0.8055 - val_accuracy: 0.8279
Epoch 19/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9333 - accuracy: 0.8171 - val_loss: 0.7731 - val_accuracy: 0.8229
Epoch 20/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9340 - accuracy: 0.8173 - val_loss: 0.7649 - val_accuracy: 0.8213
Epoch 21/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9333 - accuracy: 0.8177 - val_loss: 0.7801 - val_accuracy: 0.8222
Epoch 22/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9342 - accuracy: 0.8169 - val_loss: 0.7797 - val_accuracy: 0.8237
Epoch 23/30
4362/4362 [==============================] - 539s 124ms/step - loss: 1.9306 - accuracy: 0.8175 - val_loss: 0.7543 - val_accuracy: 0.8219
Epoch 24/30
4362/4362 [==============================] - 538s 123ms/step - loss: 1.9315 - accuracy: 0.8179 - val_loss: 0.7604 - val_accuracy: 0.8214
Epoch 25/30
4362/4362 [==============================] - 538s 123ms/step - loss: 1.9284 - accuracy: 0.8175 - val_loss: 0.7643 - val_accuracy: 0.8213
Epoch 26/30
4362/4362 [==============================] - 538s 123ms/step - loss: 1.9329 - accuracy: 0.8171 - val_loss: 0.7685 - val_accuracy: 0.8211
Epoch 27/30
4362/4362 [==============================] - 538s 123ms/step - loss: 1.9343 - accuracy: 0.8172 - val_loss: 0.7992 - val_accuracy: 0.8226
Epoch 28/30
4362/4362 [==============================] - 539s 124ms/step - loss: 1.9295 - accuracy: 0.8173 - val_loss: 0.7643 - val_accuracy: 0.8222
Epoch 29/30
4362/4362 [==============================] - 539s 124ms/step - loss: 1.9292 - accuracy: 0.8183 - val_loss: 0.7670 - val_accuracy: 0.8216
Epoch 30/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9286 - accuracy: 0.8175 - val_loss: 0.7716 - val_accuracy: 0.8230
[INFO] evaluating network...
2022-10-21 21:54:47.342422: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 571748352 exceeds 10% of free system memory.
1091/1091 [==============================] - 26s 24ms/step
              precision    recall  f1-score   support

           0       0.68      0.78      0.72      6917
           1       0.69      0.51      0.59      7675
           2       0.99      0.86      0.92      6841
           3       1.00      0.99      0.99      7029
           4       0.99      0.93      0.96      6707
           5       0.95      0.94      0.95      6283
           6       0.99      0.93      0.96      6847
           7       0.99      0.99      0.99      7151
           8       0.99      0.96      0.98      6789
           9       0.95      0.93      0.94      6770
           A       0.94      0.99      0.96      1281
           B       0.87      1.00      0.93       776
           C       0.80      0.74      0.77      2019
           D       0.73      0.97      0.83       912
           E       0.91      0.99      0.95       987
           F       0.81      0.87      0.84      1836
           G       0.62      0.96      0.76       503
           H       0.89      0.99      0.94       630
           I       0.65      0.44      0.52      2389
           J       0.81      0.94      0.87       752
           K       0.63      0.94      0.76       494
           L       0.81      0.97      0.88      1015
           M       0.84      0.65      0.73      1800
           N       0.95      0.98      0.97      1647
           O       0.63      0.36      0.46      4997
           P       0.81      0.95      0.87      1669
           Q       0.76      0.98      0.86       521
           R       0.89      0.99      0.94      1015
           S       0.83      0.71      0.76      4153
           T       0.86      0.96      0.90      1964
           U       0.82      0.79      0.80      2520
           V       0.66      0.73      0.69       927
           W       0.72      0.96      0.82       939
           X       0.62      0.94      0.75       554
           Y       0.56      0.94      0.70       949
           Z       0.33      0.95      0.49       540
           a       0.96      0.90      0.93      2007
           b       0.81      0.93      0.87      1032
           c       0.34      0.44      0.38       571
           d       0.97      0.98      0.98      2035
           e       0.99      0.96      0.98      4926
           f       0.44      0.39      0.41       512
           g       0.59      0.66      0.62       737
           h       0.95      0.96      0.95      1748
           i       0.43      0.54      0.48       545
           j       0.73      0.65      0.69       379
           k       0.86      0.47      0.61       498
           l       0.31      0.57      0.40      3064
           m       0.34      0.62      0.44       529
           n       0.97      0.93      0.95      2284
           o       0.11      0.27      0.16       550
           p       0.64      0.32      0.43       490
           q       0.49      0.63      0.55       599
           r       0.99      0.93      0.96      2821
           s       0.16      0.33      0.21       540
           t       0.98      0.89      0.93      3653
           u       0.33      0.44      0.38       566
           v       0.52      0.45      0.48       582
           w       0.84      0.40      0.54       539
           x       0.87      0.44      0.59       564
           y       0.58      0.29      0.38       473
           z       0.53      0.37      0.43       545

    accuracy                           0.82    139587
   macro avg       0.74      0.76      0.73    139587
weighted avg       0.85      0.82      0.83    139587

[INFO] serializing network...
1/1 [==============================] - 0s 234ms/step
1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 16ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 16ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 40ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 30ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 30ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 31ms/step
started training session 1
[INFO] loading existing model...
[INFO] training network...
training started at: 2022-10-21 21:56:06
Epoch 1/30
4362/4362 [==============================] - ETA: 0s - loss: 1.9284 - accuracy: 0.81782022-10-21 22:04:01.557834: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 571748352 exceeds 10% of free system memory.
4362/4362 [==============================] - 545s 124ms/step - loss: 1.9284 - accuracy: 0.8178 - val_loss: 0.7745 - val_accuracy: 0.8204
Epoch 2/30
4362/4362 [==============================] - 543s 125ms/step - loss: 1.9253 - accuracy: 0.8177 - val_loss: 0.7749 - val_accuracy: 0.8203
Epoch 3/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9296 - accuracy: 0.8173 - val_loss: 0.7828 - val_accuracy: 0.8223
Epoch 4/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9254 - accuracy: 0.8176 - val_loss: 0.7685 - val_accuracy: 0.8217
Epoch 5/30
4362/4362 [==============================] - 543s 124ms/step - loss: 1.9268 - accuracy: 0.8183 - val_loss: 0.7823 - val_accuracy: 0.8208
Epoch 6/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9259 - accuracy: 0.8185 - val_loss: 0.7833 - val_accuracy: 0.8200
Epoch 7/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9246 - accuracy: 0.8178 - val_loss: 0.7690 - val_accuracy: 0.8222
Epoch 8/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9244 - accuracy: 0.8182 - val_loss: 0.8016 - val_accuracy: 0.8223
Epoch 9/30
4362/4362 [==============================] - 543s 125ms/step - loss: 1.9248 - accuracy: 0.8184 - val_loss: 0.7803 - val_accuracy: 0.8231
Epoch 10/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9233 - accuracy: 0.8180 - val_loss: 0.7672 - val_accuracy: 0.8229
Epoch 11/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9243 - accuracy: 0.8183 - val_loss: 0.8060 - val_accuracy: 0.8239
Epoch 12/30
4362/4362 [==============================] - 543s 125ms/step - loss: 1.9250 - accuracy: 0.8179 - val_loss: 0.7650 - val_accuracy: 0.8237
Epoch 13/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9226 - accuracy: 0.8180 - val_loss: 0.7685 - val_accuracy: 0.8237
Epoch 14/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9195 - accuracy: 0.8192 - val_loss: 0.7798 - val_accuracy: 0.8217
Epoch 15/30
4362/4362 [==============================] - 543s 124ms/step - loss: 1.9204 - accuracy: 0.8179 - val_loss: 0.7666 - val_accuracy: 0.8214
Epoch 16/30
4362/4362 [==============================] - 545s 125ms/step - loss: 1.9224 - accuracy: 0.8187 - val_loss: 0.7851 - val_accuracy: 0.8232
Epoch 17/30
4362/4362 [==============================] - 542s 124ms/step - loss: 1.9205 - accuracy: 0.8186 - val_loss: 0.7889 - val_accuracy: 0.8218
Epoch 18/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9217 - accuracy: 0.8182 - val_loss: 0.7837 - val_accuracy: 0.8209
Epoch 19/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9194 - accuracy: 0.8184 - val_loss: 0.7747 - val_accuracy: 0.8240
Epoch 20/30
4362/4362 [==============================] - 543s 125ms/step - loss: 1.9186 - accuracy: 0.8190 - val_loss: 0.7773 - val_accuracy: 0.8219
Epoch 21/30
4362/4362 [==============================] - 543s 124ms/step - loss: 1.9177 - accuracy: 0.8190 - val_loss: 0.8008 - val_accuracy: 0.8209
Epoch 22/30
4362/4362 [==============================] - 542s 124ms/step - loss: 1.9184 - accuracy: 0.8185 - val_loss: 0.7871 - val_accuracy: 0.8203
Epoch 23/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9178 - accuracy: 0.8185 - val_loss: 0.7780 - val_accuracy: 0.8229
Epoch 24/30
4362/4362 [==============================] - 543s 124ms/step - loss: 1.9171 - accuracy: 0.8189 - val_loss: 0.7982 - val_accuracy: 0.8223
Epoch 25/30
4362/4362 [==============================] - 543s 124ms/step - loss: 1.9183 - accuracy: 0.8191 - val_loss: 0.7779 - val_accuracy: 0.8204
Epoch 26/30
4362/4362 [==============================] - 542s 124ms/step - loss: 1.9140 - accuracy: 0.8188 - val_loss: 0.7952 - val_accuracy: 0.8232
Epoch 27/30
4362/4362 [==============================] - 543s 124ms/step - loss: 1.9164 - accuracy: 0.8191 - val_loss: 0.7683 - val_accuracy: 0.8207
Epoch 28/30
4362/4362 [==============================] - 543s 124ms/step - loss: 1.9178 - accuracy: 0.8189 - val_loss: 0.7725 - val_accuracy: 0.8203
Epoch 29/30
4362/4362 [==============================] - 544s 125ms/step - loss: 1.9177 - accuracy: 0.8193 - val_loss: 0.7917 - val_accuracy: 0.8211
Epoch 30/30
4362/4362 [==============================] - 543s 124ms/step - loss: 1.9147 - accuracy: 0.8188 - val_loss: 0.7667 - val_accuracy: 0.8216
[INFO] evaluating network...
2022-10-22 02:27:50.455741: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 571748352 exceeds 10% of free system memory.
1091/1091 [==============================] - 26s 23ms/step
              precision    recall  f1-score   support

           0       0.69      0.79      0.74      6917
           1       0.72      0.49      0.58      7675
           2       0.99      0.86      0.92      6841
           3       1.00      0.99      0.99      7029
           4       0.99      0.93      0.96      6707
           5       0.94      0.94      0.94      6283
           6       0.99      0.93      0.96      6847
           7       0.99      0.99      0.99      7151
           8       0.99      0.96      0.98      6789
           9       0.96      0.91      0.93      6770
           A       0.95      0.98      0.96      1281
           B       0.87      1.00      0.93       776
           C       0.82      0.68      0.75      2019
           D       0.72      0.97      0.82       912
           E       0.93      0.99      0.96       987
           F       0.82      0.84      0.83      1836
           G       0.64      0.96      0.77       503
           H       0.91      0.99      0.95       630
           I       0.61      0.46      0.53      2389
           J       0.84      0.93      0.88       752
           K       0.64      0.93      0.76       494
           L       0.83      0.97      0.90      1015
           M       0.84      0.61      0.71      1800
           N       0.95      0.98      0.97      1647
           O       0.68      0.32      0.44      4997
           P       0.82      0.92      0.87      1669
           Q       0.76      0.98      0.86       521
           R       0.90      0.99      0.94      1015
           S       0.84      0.68      0.75      4153
           T       0.88      0.95      0.91      1964
           U       0.84      0.75      0.79      2520
           V       0.67      0.71      0.69       927
           W       0.75      0.94      0.84       939
           X       0.64      0.92      0.75       554
           Y       0.59      0.91      0.71       949
           Z       0.35      0.93      0.51       540
           a       0.96      0.91      0.93      2007
           b       0.78      0.94      0.85      1032
           c       0.34      0.54      0.41       571
           d       0.98      0.98      0.98      2035
           e       0.99      0.97      0.98      4926
           f       0.42      0.45      0.43       512
           g       0.57      0.66      0.61       737
           h       0.95      0.96      0.96      1748
           i       0.36      0.58      0.44       545
           j       0.71      0.71      0.71       379
           k       0.86      0.49      0.62       498
           l       0.32      0.58      0.41      3064
           m       0.33      0.65      0.44       529
           n       0.97      0.93      0.95      2284
           o       0.10      0.31      0.15       550
           p       0.61      0.42      0.49       490
           q       0.43      0.67      0.52       599
           r       0.99      0.94      0.96      2821
           s       0.15      0.36      0.22       540
           t       0.97      0.90      0.94      3653
           u       0.34      0.53      0.41       566
           v       0.51      0.49      0.50       582
           w       0.82      0.50      0.62       539
           x       0.85      0.49      0.63       564
           y       0.56      0.43      0.49       473
           z       0.49      0.45      0.47       545

    accuracy                           0.82    139587
   macro avg       0.74      0.77      0.74    139587
weighted avg       0.85      0.82      0.83    139587

[INFO] serializing network...
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 16ms/step
1/1 [==============================] - 0s 16ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 42ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 14ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 29ms/step
started training session 2
[INFO] loading existing model...
[INFO] training network...
training started at: 2022-10-22 02:29:09
Epoch 1/30
4362/4362 [==============================] - ETA: 0s - loss: 1.9154 - accuracy: 0.81902022-10-22 02:37:02.981494: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 571748352 exceeds 10% of free system memory.
4362/4362 [==============================] - 542s 124ms/step - loss: 1.9154 - accuracy: 0.8190 - val_loss: 0.7985 - val_accuracy: 0.8206
Epoch 2/30
4362/4362 [==============================] - 541s 124ms/step - loss: 1.9139 - accuracy: 0.8196 - val_loss: 0.7671 - val_accuracy: 0.8218
Epoch 3/30
4362/4362 [==============================] - 540s 124ms/step - loss: 1.9163 - accuracy: 0.8184 - val_loss: 0.7771 - val_accuracy: 0.8235
Epoch 4/30
4362/4362 [==============================] - 541s 124ms/step - loss: 1.9126 - accuracy: 0.8197 - val_loss: 0.7718 - val_accuracy: 0.8207
Epoch 5/30
4362/4362 [==============================] - 542s 124ms/step - loss: 1.9135 - accuracy: 0.8192 - val_loss: 0.7792 - val_accuracy: 0.8216
Epoch 6/30
4362/4362 [==============================] - 541s 124ms/step - loss: 1.9124 - accuracy: 0.8190 - val_loss: 0.7816 - val_accuracy: 0.8204
Epoch 7/30
4362/4362 [==============================] - 537s 123ms/step - loss: 1.9124 - accuracy: 0.8195 - val_loss: 0.7560 - val_accuracy: 0.8222
Epoch 8/30
4362/4362 [==============================] - 530s 121ms/step - loss: 1.9146 - accuracy: 0.8192 - val_loss: 0.7721 - val_accuracy: 0.8205
Epoch 9/30
4362/4362 [==============================] - 529s 121ms/step - loss: 1.9145 - accuracy: 0.8188 - val_loss: 0.7555 - val_accuracy: 0.8241
Epoch 10/30
4362/4362 [==============================] - 530s 121ms/step - loss: 1.9139 - accuracy: 0.8193 - val_loss: 0.7558 - val_accuracy: 0.8238
Epoch 11/30
4362/4362 [==============================] - 532s 122ms/step - loss: 1.9148 - accuracy: 0.8188 - val_loss: 0.7680 - val_accuracy: 0.8224
Epoch 12/30
4362/4362 [==============================] - 530s 121ms/step - loss: 1.9112 - accuracy: 0.8195 - val_loss: 0.7950 - val_accuracy: 0.8197
Epoch 13/30
4362/4362 [==============================] - 531s 122ms/step - loss: 1.9099 - accuracy: 0.8198 - val_loss: 0.7721 - val_accuracy: 0.8189
Epoch 14/30
4362/4362 [==============================] - 530s 121ms/step - loss: 1.9133 - accuracy: 0.8191 - val_loss: 0.7763 - val_accuracy: 0.8226
Epoch 15/30
4362/4362 [==============================] - 531s 122ms/step - loss: 1.9103 - accuracy: 0.8197 - val_loss: 0.7625 - val_accuracy: 0.8209
Epoch 16/30
4362/4362 [==============================] - 530s 122ms/step - loss: 1.9107 - accuracy: 0.8194 - val_loss: 0.7795 - val_accuracy: 0.8213
Epoch 17/30
4362/4362 [==============================] - 530s 122ms/step - loss: 1.9113 - accuracy: 0.8196 - val_loss: 0.7794 - val_accuracy: 0.8183
Epoch 18/30
4362/4362 [==============================] - 531s 122ms/step - loss: 1.9107 - accuracy: 0.8191 - val_loss: 0.7608 - val_accuracy: 0.8206
Epoch 19/30
4362/4362 [==============================] - 530s 121ms/step - loss: 1.9091 - accuracy: 0.8195 - val_loss: 0.7637 - val_accuracy: 0.8227
Epoch 20/30
4362/4362 [==============================] - 530s 122ms/step - loss: 1.9086 - accuracy: 0.8193 - val_loss: 0.7583 - val_accuracy: 0.8212
Epoch 21/30
4362/4362 [==============================] - 530s 122ms/step - loss: 1.9089 - accuracy: 0.8190 - val_loss: 0.7695 - val_accuracy: 0.8236
Epoch 22/30
4362/4362 [==============================] - 531s 122ms/step - loss: 1.9119 - accuracy: 0.8188 - val_loss: 0.7725 - val_accuracy: 0.8213
Epoch 23/30
4362/4362 [==============================] - 530s 122ms/step - loss: 1.9077 - accuracy: 0.8198 - val_loss: 0.7707 - val_accuracy: 0.8184
Epoch 24/30
4362/4362 [==============================] - 531s 122ms/step - loss: 1.9118 - accuracy: 0.8193 - val_loss: 0.7652 - val_accuracy: 0.8219
Epoch 25/30
4362/4362 [==============================] - 531s 122ms/step - loss: 1.9073 - accuracy: 0.8191 - val_loss: 0.7719 - val_accuracy: 0.8230
Epoch 26/30
4362/4362 [==============================] - 531s 122ms/step - loss: 1.9075 - accuracy: 0.8195 - val_loss: 0.7638 - val_accuracy: 0.8234
Epoch 27/30
4362/4362 [==============================] - 531s 122ms/step - loss: 1.9076 - accuracy: 0.8196 - val_loss: 0.7719 - val_accuracy: 0.8200
Epoch 28/30
4362/4362 [==============================] - 530s 121ms/step - loss: 1.9060 - accuracy: 0.8200 - val_loss: 0.7787 - val_accuracy: 0.8189
Epoch 29/30
4362/4362 [==============================] - 532s 122ms/step - loss: 1.9071 - accuracy: 0.8205 - val_loss: 0.7955 - val_accuracy: 0.8199
Epoch 30/30
4362/4362 [==============================] - 542s 124ms/step - loss: 1.9065 - accuracy: 0.8189 - val_loss: 0.7649 - val_accuracy: 0.8203
[INFO] evaluating network...
1091/1091 [==============================] - 26s 23ms/step
              precision    recall  f1-score   support

           0       0.69      0.78      0.73      6917
           1       0.73      0.45      0.55      7675
           2       0.99      0.86      0.92      6841
           3       1.00      0.99      0.99      7029
           4       0.99      0.93      0.96      6707
           5       0.95      0.94      0.94      6283
           6       0.99      0.93      0.96      6847
           7       0.99      0.99      0.99      7151
           8       0.99      0.96      0.97      6789
           9       0.96      0.91      0.94      6770
           A       0.94      0.99      0.96      1281
           B       0.87      1.00      0.93       776
           C       0.81      0.70      0.75      2019
           D       0.73      0.96      0.83       912
           E       0.93      0.99      0.96       987
           F       0.83      0.82      0.83      1836
           G       0.63      0.96      0.76       503
           H       0.91      0.99      0.95       630
           I       0.59      0.49      0.54      2389
           J       0.84      0.93      0.88       752
           K       0.64      0.92      0.76       494
           L       0.82      0.97      0.89      1015
           M       0.84      0.64      0.72      1800
           N       0.96      0.98      0.97      1647
           O       0.65      0.33      0.44      4997
           P       0.82      0.93      0.87      1669
           Q       0.78      0.98      0.87       521
           R       0.90      0.98      0.94      1015
           S       0.84      0.67      0.75      4153
           T       0.88      0.95      0.92      1964
           U       0.84      0.75      0.79      2520
           V       0.67      0.71      0.69       927
           W       0.75      0.94      0.83       939
           X       0.64      0.91      0.75       554
           Y       0.59      0.92      0.72       949
           Z       0.34      0.94      0.50       540
           a       0.96      0.91      0.93      2007
           b       0.81      0.93      0.86      1032
           c       0.35      0.54      0.42       571
           d       0.98      0.97      0.98      2035
           e       0.99      0.97      0.98      4926
           f       0.41      0.49      0.45       512
           g       0.57      0.66      0.61       737
           h       0.95      0.96      0.95      1748
           i       0.39      0.58      0.47       545
           j       0.72      0.68      0.70       379
           k       0.84      0.51      0.63       498
           l       0.31      0.60      0.41      3064
           m       0.34      0.64      0.45       529
           n       0.97      0.93      0.95      2284
           o       0.10      0.32      0.15       550
           p       0.61      0.40      0.48       490
           q       0.44      0.67      0.53       599
           r       0.99      0.94      0.96      2821
           s       0.15      0.37      0.22       540
           t       0.97      0.91      0.94      3653
           u       0.33      0.54      0.41       566
           v       0.52      0.48      0.50       582
           w       0.82      0.46      0.59       539
           x       0.86      0.48      0.62       564
           y       0.61      0.38      0.47       473
           z       0.50      0.43      0.46       545

    accuracy                           0.82    139587
   macro avg       0.74      0.77      0.74    139587
weighted avg       0.85      0.82      0.83    139587

[INFO] serializing network...
1/1 [==============================] - 0s 16ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
started training session 3
[INFO] loading existing model...
[INFO] training network...
training started at: 2022-10-22 06:57:02
Epoch 1/30
4362/4362 [==============================] - 550s 126ms/step - loss: 1.9066 - accuracy: 0.8200 - val_loss: 0.7714 - val_accuracy: 0.8207
Epoch 2/30
4362/4362 [==============================] - 549s 126ms/step - loss: 1.9051 - accuracy: 0.8197 - val_loss: 0.7801 - val_accuracy: 0.8210
Epoch 3/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9036 - accuracy: 0.8203 - val_loss: 0.7747 - val_accuracy: 0.8202
Epoch 4/30
4362/4362 [==============================] - 547s 126ms/step - loss: 1.9065 - accuracy: 0.8197 - val_loss: 0.7717 - val_accuracy: 0.8200
Epoch 5/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9020 - accuracy: 0.8196 - val_loss: 0.7705 - val_accuracy: 0.8218
Epoch 6/30
4362/4362 [==============================] - 547s 125ms/step - loss: 1.9042 - accuracy: 0.8204 - val_loss: 0.7826 - val_accuracy: 0.8195
Epoch 7/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9043 - accuracy: 0.8201 - val_loss: 0.7737 - val_accuracy: 0.8218
Epoch 8/30
4362/4362 [==============================] - 549s 126ms/step - loss: 1.9043 - accuracy: 0.8198 - val_loss: 0.7774 - val_accuracy: 0.8206
Epoch 9/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9062 - accuracy: 0.8204 - val_loss: 0.7761 - val_accuracy: 0.8184
Epoch 10/30
4362/4362 [==============================] - 547s 125ms/step - loss: 1.9027 - accuracy: 0.8199 - val_loss: 0.7805 - val_accuracy: 0.8206
Epoch 11/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9058 - accuracy: 0.8209 - val_loss: 0.7656 - val_accuracy: 0.8213
Epoch 12/30
4362/4362 [==============================] - 547s 125ms/step - loss: 1.9036 - accuracy: 0.8197 - val_loss: 0.7784 - val_accuracy: 0.8197
Epoch 13/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9012 - accuracy: 0.8198 - val_loss: 0.7670 - val_accuracy: 0.8200
Epoch 14/30
4362/4362 [==============================] - 549s 126ms/step - loss: 1.9018 - accuracy: 0.8202 - val_loss: 0.7758 - val_accuracy: 0.8219
Epoch 15/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9014 - accuracy: 0.8203 - val_loss: 0.7776 - val_accuracy: 0.8210
Epoch 16/30
4362/4362 [==============================] - 547s 125ms/step - loss: 1.9018 - accuracy: 0.8206 - val_loss: 0.7769 - val_accuracy: 0.8200
Epoch 17/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9010 - accuracy: 0.8200 - val_loss: 0.7798 - val_accuracy: 0.8205
Epoch 18/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9019 - accuracy: 0.8206 - val_loss: 0.7647 - val_accuracy: 0.8220
Epoch 19/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9004 - accuracy: 0.8203 - val_loss: 0.7768 - val_accuracy: 0.8218
Epoch 20/30
4362/4362 [==============================] - 547s 125ms/step - loss: 1.9023 - accuracy: 0.8201 - val_loss: 0.7741 - val_accuracy: 0.8197
Epoch 21/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.8983 - accuracy: 0.8205 - val_loss: 0.7738 - val_accuracy: 0.8186
Epoch 22/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9001 - accuracy: 0.8205 - val_loss: 0.7762 - val_accuracy: 0.8218
Epoch 23/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9001 - accuracy: 0.8200 - val_loss: 0.7796 - val_accuracy: 0.8201
Epoch 24/30
4362/4362 [==============================] - 547s 125ms/step - loss: 1.8982 - accuracy: 0.8204 - val_loss: 0.7583 - val_accuracy: 0.8213
Epoch 25/30
4362/4362 [==============================] - 547s 125ms/step - loss: 1.9001 - accuracy: 0.8205 - val_loss: 0.7691 - val_accuracy: 0.8202
Epoch 26/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9003 - accuracy: 0.8203 - val_loss: 0.7568 - val_accuracy: 0.8217
Epoch 27/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.9005 - accuracy: 0.8200 - val_loss: 0.7627 - val_accuracy: 0.8193
Epoch 28/30
4362/4362 [==============================] - 547s 125ms/step - loss: 1.8999 - accuracy: 0.8196 - val_loss: 0.7665 - val_accuracy: 0.8222
Epoch 29/30
4362/4362 [==============================] - 547s 126ms/step - loss: 1.8985 - accuracy: 0.8206 - val_loss: 0.7833 - val_accuracy: 0.8203
Epoch 30/30
4362/4362 [==============================] - 548s 126ms/step - loss: 1.8978 - accuracy: 0.8204 - val_loss: 0.7588 - val_accuracy: 0.8211
[INFO] evaluating network...
1091/1091 [==============================] - 26s 24ms/step
              precision    recall  f1-score   support

           0       0.69      0.77      0.73      6917
           1       0.72      0.51      0.60      7675
           2       0.99      0.86      0.92      6841
           3       1.00      0.99      0.99      7029
           4       0.99      0.93      0.96      6707
           5       0.94      0.94      0.94      6283
           6       0.99      0.92      0.96      6847
           7       0.99      0.99      0.99      7151
           8       0.99      0.96      0.98      6789
           9       0.96      0.92      0.94      6770
           A       0.94      0.99      0.96      1281
           B       0.86      1.00      0.92       776
           C       0.82      0.69      0.75      2019
           D       0.72      0.97      0.82       912
           E       0.94      0.99      0.96       987
           F       0.83      0.82      0.83      1836
           G       0.64      0.96      0.77       503
           H       0.91      0.98      0.94       630
           I       0.62      0.46      0.53      2389
           J       0.84      0.93      0.88       752
           K       0.64      0.93      0.76       494
           L       0.83      0.97      0.90      1015
           M       0.85      0.60      0.71      1800
           N       0.95      0.98      0.97      1647
           O       0.66      0.31      0.42      4997
           P       0.82      0.93      0.87      1669
           Q       0.78      0.98      0.87       521
           R       0.91      0.99      0.94      1015
           S       0.84      0.64      0.72      4153
           T       0.88      0.95      0.92      1964
           U       0.84      0.75      0.79      2520
           V       0.67      0.72      0.69       927
           W       0.76      0.94      0.84       939
           X       0.63      0.92      0.75       554
           Y       0.59      0.91      0.72       949
           Z       0.35      0.93      0.51       540
           a       0.96      0.91      0.93      2007
           b       0.77      0.94      0.84      1032
           c       0.34      0.54      0.42       571
           d       0.98      0.98      0.98      2035
           e       0.99      0.97      0.98      4926
           f       0.42      0.50      0.45       512
           g       0.59      0.66      0.62       737
           h       0.95      0.96      0.96      1748
           i       0.39      0.58      0.47       545
           j       0.72      0.70      0.71       379
           k       0.85      0.49      0.62       498
           l       0.32      0.57      0.41      3064
           m       0.33      0.67      0.44       529
           n       0.97      0.94      0.95      2284
           o       0.10      0.35      0.15       550
           p       0.61      0.39      0.48       490
           q       0.46      0.66      0.54       599
           r       0.99      0.94      0.96      2821
           s       0.15      0.41      0.22       540
           t       0.97      0.91      0.94      3653
           u       0.34      0.54      0.42       566
           v       0.51      0.48      0.50       582
           w       0.81      0.50      0.62       539
           x       0.86      0.48      0.61       564
           y       0.59      0.40      0.48       473
           z       0.49      0.47      0.48       545

    accuracy                           0.82    139587
   macro avg       0.74      0.77      0.74    139587
weighted avg       0.85      0.82      0.83    139587

[INFO] serializing network...
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 35ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
started training session 4
[INFO] loading existing model...
[INFO] training network...
training started at: 2022-10-22 11:32:19
Epoch 1/30
4362/4362 [==============================] - 541s 124ms/step - loss: 1.8993 - accuracy: 0.8209 - val_loss: 0.7773 - val_accuracy: 0.8176
Epoch 2/30
4362/4362 [==============================] - 539s 123ms/step - loss: 1.8989 - accuracy: 0.8199 - val_loss: 0.7759 - val_accuracy: 0.8207
Epoch 3/30
4362/4362 [==============================] - 538s 123ms/step - loss: 1.8943 - accuracy: 0.8213 - val_loss: 0.7576 - val_accuracy: 0.8210
Epoch 4/30
4362/4362 [==============================] - 541s 124ms/step - loss: 1.8971 - accuracy: 0.8198 - val_loss: 0.7722 - val_accuracy: 0.8199
Epoch 5/30
4362/4362 [==============================] - 530s 122ms/step - loss: 1.8963 - accuracy: 0.8208 - val_loss: 0.7764 - val_accuracy: 0.8213
Epoch 6/30
4362/4362 [==============================] - 530s 121ms/step - loss: 1.8974 - accuracy: 0.8207 - val_loss: 0.7673 - val_accuracy: 0.8192
Epoch 7/30
4362/4362 [==============================] - 529s 121ms/step - loss: 1.8964 - accuracy: 0.8210 - val_loss: 0.7727 - val_accuracy: 0.8212
Epoch 8/30
4362/4362 [==============================] - 528s 121ms/step - loss: 1.8971 - accuracy: 0.8210 - val_loss: 0.7795 - val_accuracy: 0.8189
Epoch 9/30
4362/4362 [==============================] - 528s 121ms/step - loss: 1.8961 - accuracy: 0.8199 - val_loss: 0.7687 - val_accuracy: 0.8201
Epoch 10/30
4362/4362 [==============================] - 529s 121ms/step - loss: 1.8996 - accuracy: 0.8206 - val_loss: 0.7586 - val_accuracy: 0.8221
Epoch 11/30
4362/4362 [==============================] - 528s 121ms/step - loss: 1.8950 - accuracy: 0.8205 - val_loss: 0.7585 - val_accuracy: 0.8222
Epoch 12/30
4362/4362 [==============================] - 528s 121ms/step - loss: 1.8958 - accuracy: 0.8205 - val_loss: 0.7730 - val_accuracy: 0.8192
Epoch 13/30
4362/4362 [==============================] - 528s 121ms/step - loss: 1.8977 - accuracy: 0.8206 - val_loss: 0.7708 - val_accuracy: 0.8196
Epoch 14/30
4362/4362 [==============================] - 528s 121ms/step - loss: 1.8975 - accuracy: 0.8201 - val_loss: 0.7671 - val_accuracy: 0.8204
Epoch 15/30
4362/4362 [==============================] - 528s 121ms/step - loss: 1.8945 - accuracy: 0.8208 - val_loss: 0.7717 - val_accuracy: 0.8192
