PS D:\Users\jmuts\Documenten\school\jaar 4\Semester 7 Artificial intelligence\personal\code\pyImageSearch>  & 'C:\Users\jmuts\AppData\Local\Programs\Python\Python310\python.exe' 'c:\Users\jmuts\.vscode\extensions\ms-python.python-2022.16.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '64991' '--' 'd:\Users\jmuts\Documenten\school\jaar 4\Semester 7 Artificial intelligence\personal\code\pyImageSearch\ocr-keras-tensorflow\train_ocr_model.py'
cuda_malloc_async
run started at: 2022-10-24 19:57:59
[INFO] loading datasets...
[INFO] datasets loaded.
started training session 1
[INFO] loading existing model...
2022-10-24 20:04:43.457711: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-24 20:04:44.912632: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2022-10-24 20:04:44.923058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4626 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1
[INFO] training network...
training started at: 2022-10-24 20:04:46
Epoch 1/20
2022-10-24 20:04:51.666182: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500
10243/10243 [==============================] - ETA: 0s - loss: 1.9395 - accuracy: 0.83732022-10-24 20:20:49.372478: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1006948352 exceeds 10% of free 
system memory.
10243/10243 [==============================] - 1134s 110ms/step - loss: 1.9395 - accuracy: 0.8373 - val_loss: 0.8166 - val_accuracy: 0.7850
Epoch 2/20
10243/10243 [==============================] - 1120s 109ms/step - loss: 1.9367 - accuracy: 0.8373 - val_loss: 1.2884 - val_accuracy: 0.7850
Epoch 3/20
10243/10243 [==============================] - 1142s 111ms/step - loss: 1.9369 - accuracy: 0.8380 - val_loss: 0.6501 - val_accuracy: 0.8680
Epoch 4/20
10243/10243 [==============================] - 1141s 111ms/step - loss: 1.9347 - accuracy: 0.8378 - val_loss: 0.6509 - val_accuracy: 0.8690
Epoch 5/20
10243/10243 [==============================] - 1135s 111ms/step - loss: 1.9344 - accuracy: 0.8378 - val_loss: 1.5644 - val_accuracy: 0.7521
Epoch 6/20
10243/10243 [==============================] - 1143s 112ms/step - loss: 1.9366 - accuracy: 0.8376 - val_loss: 0.6767 - val_accuracy: 0.8682
Epoch 7/20
10243/10243 [==============================] - 1147s 112ms/step - loss: 1.9342 - accuracy: 0.8374 - val_loss: 0.6498 - val_accuracy: 0.8691
Epoch 8/20
10243/10243 [==============================] - 1142s 111ms/step - loss: 1.9321 - accuracy: 0.8381 - val_loss: 0.7533 - val_accuracy: 0.8604
Epoch 9/20
10243/10243 [==============================] - 1123s 110ms/step - loss: 1.9312 - accuracy: 0.8378 - val_loss: 0.6379 - val_accuracy: 0.8685
Epoch 10/20
10243/10243 [==============================] - 1143s 112ms/step - loss: 1.9313 - accuracy: 0.8381 - val_loss: 0.6668 - val_accuracy: 0.8520
Epoch 11/20
10243/10243 [==============================] - 1140s 111ms/step - loss: 1.9305 - accuracy: 0.8384 - val_loss: 0.6742 - val_accuracy: 0.8693
Epoch 12/20
10243/10243 [==============================] - 1139s 111ms/step - loss: 1.9303 - accuracy: 0.8382 - val_loss: 0.8722 - val_accuracy: 0.8415
Epoch 13/20
10243/10243 [==============================] - 1139s 111ms/step - loss: 1.9290 - accuracy: 0.8384 - val_loss: 0.8981 - val_accuracy: 0.8376
Epoch 14/20
10243/10243 [==============================] - 1135s 111ms/step - loss: 1.9275 - accuracy: 0.8381 - val_loss: 0.6526 - val_accuracy: 0.8697
Epoch 15/20
10243/10243 [==============================] - 1138s 111ms/step - loss: 1.9286 - accuracy: 0.8385 - val_loss: 0.6558 - val_accuracy: 0.8692
Epoch 16/20
10243/10243 [==============================] - 1139s 111ms/step - loss: 1.9272 - accuracy: 0.8382 - val_loss: 0.6391 - val_accuracy: 0.8673
Epoch 17/20
10243/10243 [==============================] - 1137s 111ms/step - loss: 1.9268 - accuracy: 0.8381 - val_loss: 0.6636 - val_accuracy: 0.8705
Epoch 18/20
10243/10243 [==============================] - 1141s 111ms/step - loss: 1.9237 - accuracy: 0.8382 - val_loss: 0.6540 - val_accuracy: 0.8705
Epoch 19/20
10243/10243 [==============================] - 1136s 111ms/step - loss: 1.9252 - accuracy: 0.8384 - val_loss: 0.6454 - val_accuracy: 0.8690
Epoch 20/20
10243/10243 [==============================] - 1135s 111ms/step - loss: 1.9287 - accuracy: 0.8384 - val_loss: 0.6776 - val_accuracy: 0.8696
[INFO] serializing network...
[INFO] evaluating network...
2022-10-25 02:25:42.651054: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1006948352 exceeds 10% of free system memory.
2561/2561 [==============================] - 54s 21ms/step
              precision    recall  f1-score   support

           0       0.64      0.65      0.65      8298
           1       0.66      0.88      0.75      9250
           2       0.98      0.87      0.92      8239
           3       1.00      0.98      0.99      8457
           4       0.98      0.92      0.95      8072
           5       0.97      0.86      0.91      7546
           6       0.99      0.90      0.94      8222
           7       0.99      0.98      0.98      8609
           8       0.99      0.96      0.98      8154
           9       0.93      0.96      0.94      8161
           A       0.97      0.99      0.98      4326
           B       0.96      0.99      0.97      2800
           C       0.91      0.91      0.91      7190
           D       0.85      0.97      0.91      3144
           E       0.97      0.99      0.98      3395
           F       0.82      0.96      0.88      2617
           G       0.77      0.98      0.86      1928
           H       0.92      0.99      0.95      2248
           I       0.74      0.49      0.59      2907
           J       0.87      0.97      0.92      2931
           K       0.81      0.98      0.89      2119
           L       0.89      0.99      0.94      3518
           M       0.87      0.96      0.91      4681
           N       0.96      0.99      0.98      5728
           O       0.85      0.74      0.79     16802
           P       0.92      0.98      0.95      6146
           Q       0.89      0.99      0.94      2013
           R       0.96      0.99      0.97      3511
           S       0.91      0.89      0.90     14320
           T       0.89      0.99      0.94      6724
           U       0.91      0.93      0.92      8826
           V       0.80      0.88      0.84      2206
           W       0.87      0.98      0.92      3656
           X       0.82      0.98      0.89      2328
           Y       0.79      0.97      0.87      3697
           Z       0.61      0.99      0.76      2277
           a       0.96      0.87      0.91      2415
           b       0.86      0.93      0.89      1420
           c       0.37      0.42      0.39       765
           d       0.98      0.98      0.98      2510
           e       1.00      0.95      0.97      5493
           f       0.60      0.20      0.30       643
           g       0.76      0.70      0.73      1142
           h       0.97      0.95      0.96      2259
           i       0.52      0.38      0.44       937
           j       0.77      0.63      0.69       579
           k       0.92      0.34      0.49       681
           l       0.34      0.14      0.19      3561
           m       0.56      0.26      0.36       796
           n       0.98      0.91      0.94      2678
           o       0.13      0.32      0.19       992
           p       0.73      0.32      0.44       568
           q       0.68      0.53      0.60       956
           r       0.99      0.90      0.94      3321
           s       0.19      0.43      0.27       735
           t       0.98      0.81      0.89      4078
           u       0.34      0.43      0.38       745
           v       0.60      0.41      0.49       825
           w       0.91      0.23      0.37       664
           x       0.91      0.38      0.54       732
           y       0.67      0.30      0.41       587
           z       0.66      0.29      0.40       709

    accuracy                           0.87    245837
   macro avg       0.81      0.76      0.77    245837
weighted avg       0.88      0.87      0.87    245837

1/1 [==============================] - 0s 227ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 56ms/step
1/1 [==============================] - 0s 59ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 35ms/step
1/1 [==============================] - 0s 65ms/step
1/1 [==============================] - 0s 58ms/step
1/1 [==============================] - 0s 57ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 66ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 59ms/step
1/1 [==============================] - 0s 57ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 50ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 39ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 81ms/step
1/1 [==============================] - 0s 58ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 54ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 60ms/step
1/1 [==============================] - 0s 41ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 48ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 52ms/step
1/1 [==============================] - 0s 50ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 50ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 57ms/step
1/1 [==============================] - 0s 66ms/step
1/1 [==============================] - 0s 52ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 57ms/step
started training session 2
[INFO] loading existing model...
[INFO] training network...
training started at: 2022-10-25 02:28:26
Epoch 1/20
10243/10243 [==============================] - ETA: 0s - loss: 1.9269 - accuracy: 0.83852022-10-25 02:44:26.615537: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1006948352 exceeds 10% of free 
system memory.
10243/10243 [==============================] - 1124s 109ms/step - loss: 1.9269 - accuracy: 0.8385 - val_loss: 0.9791 - val_accuracy: 0.8251
Epoch 2/20
10243/10243 [==============================] - 1130s 110ms/step - loss: 1.9261 - accuracy: 0.8387 - val_loss: 0.6388 - val_accuracy: 0.8698
Epoch 3/20
10243/10243 [==============================] - 1112s 109ms/step - loss: 1.9246 - accuracy: 0.8384 - val_loss: 0.6664 - val_accuracy: 0.8701
Epoch 4/20
10243/10243 [==============================] - 1039s 101ms/step - loss: 1.9260 - accuracy: 0.8384 - val_loss: 0.6354 - val_accuracy: 0.8694
Epoch 5/20
10243/10243 [==============================] - 1039s 101ms/step - loss: 1.9227 - accuracy: 0.8388 - val_loss: 0.6396 - val_accuracy: 0.8693
Epoch 6/20
10243/10243 [==============================] - 1038s 101ms/step - loss: 1.9223 - accuracy: 0.8386 - val_loss: 0.6363 - val_accuracy: 0.8672
Epoch 7/20
10243/10243 [==============================] - 1038s 101ms/step - loss: 1.9210 - accuracy: 0.8390 - val_loss: 0.6441 - val_accuracy: 0.8697
Epoch 8/20
10243/10243 [==============================] - 1037s 101ms/step - loss: 1.9201 - accuracy: 0.8389 - val_loss: 0.7669 - val_accuracy: 0.8579
Epoch 9/20
10243/10243 [==============================] - 1039s 101ms/step - loss: 1.9205 - accuracy: 0.8387 - val_loss: 0.6431 - val_accuracy: 0.8685
Epoch 10/20
10243/10243 [==============================] - 1037s 101ms/step - loss: 1.9196 - accuracy: 0.8387 - val_loss: 0.6480 - val_accuracy: 0.8596
Epoch 11/20
10243/10243 [==============================] - 1037s 101ms/step - loss: 1.9182 - accuracy: 0.8392 - val_loss: 0.6423 - val_accuracy: 0.8624
Epoch 12/20
10243/10243 [==============================] - 1038s 101ms/step - loss: 1.9215 - accuracy: 0.8389 - val_loss: 0.7271 - val_accuracy: 0.8638
Epoch 13/20
10243/10243 [==============================] - 1038s 101ms/step - loss: 1.9206 - accuracy: 0.8387 - val_loss: 0.6376 - val_accuracy: 0.8674
Epoch 14/20
10243/10243 [==============================] - 1036s 101ms/step - loss: 1.9189 - accuracy: 0.8393 - val_loss: 0.6380 - val_accuracy: 0.8666
Epoch 15/20
10243/10243 [==============================] - 1037s 101ms/step - loss: 1.9195 - accuracy: 0.8388 - val_loss: 0.6386 - val_accuracy: 0.8663
Epoch 16/20
10243/10243 [==============================] - 1037s 101ms/step - loss: 1.9211 - accuracy: 0.8387 - val_loss: 0.7669 - val_accuracy: 0.8084
Epoch 17/20
10243/10243 [==============================] - 1037s 101ms/step - loss: 1.9213 - accuracy: 0.8387 - val_loss: 0.6500 - val_accuracy: 0.8590
Epoch 18/20
10243/10243 [==============================] - 1038s 101ms/step - loss: 1.9218 - accuracy: 0.8389 - val_loss: 0.6448 - val_accuracy: 0.8715
Epoch 19/20
10243/10243 [==============================] - 1039s 101ms/step - loss: 1.9167 - accuracy: 0.8388 - val_loss: 0.9453 - val_accuracy: 0.8349
Epoch 20/20
10243/10243 [==============================] - 1095s 107ms/step - loss: 1.9167 - accuracy: 0.8396 - val_loss: 0.7105 - val_accuracy: 0.8651
[INFO] serializing network...
[INFO] evaluating network...
2022-10-25 08:19:42.249459: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1006948352 exceeds 10% of free system memory.
2561/2561 [==============================] - 54s 21ms/step
              precision    recall  f1-score   support

           0       0.64      0.56      0.59      8298
           1       0.64      0.93      0.76      9250
           2       0.97      0.87      0.92      8239
           3       1.00      0.98      0.99      8457
           4       0.99      0.89      0.94      8072
           5       0.98      0.84      0.90      7546
           6       0.99      0.90      0.94      8222
           7       0.99      0.97      0.98      8609
           8       0.99      0.96      0.98      8154
           9       0.92      0.95      0.94      8161
           A       0.97      0.99      0.98      4326
           B       0.95      0.99      0.97      2800
           C       0.90      0.93      0.91      7190
           D       0.83      0.98      0.90      3144
           E       0.96      0.99      0.97      3395
           F       0.82      0.95      0.88      2617
           G       0.75      0.98      0.85      1928
           H       0.88      0.99      0.93      2248
           I       0.75      0.45      0.56      2907
           J       0.85      0.98      0.91      2931
           K       0.79      0.99      0.88      2119
           L       0.86      0.99      0.92      3518
           M       0.85      0.97      0.91      4681
           N       0.95      0.99      0.97      5728
           O       0.80      0.78      0.79     16802
           P       0.91      0.99      0.95      6146
           Q       0.84      0.99      0.91      2013
           R       0.94      0.99      0.96      3511
           S       0.89      0.93      0.91     14320
           T       0.86      0.99      0.92      6724
           U       0.90      0.94      0.92      8826
           V       0.78      0.89      0.83      2206
           W       0.86      0.98      0.92      3656
           X       0.80      0.99      0.88      2328
           Y       0.75      0.98      0.85      3697
           Z       0.60      0.99      0.75      2277
           a       0.97      0.84      0.90      2415
           b       0.87      0.91      0.89      1420
           c       0.38      0.33      0.35       765
           d       0.98      0.98      0.98      2510
           e       1.00      0.94      0.96      5493
           f       0.61      0.17      0.27       643
           g       0.79      0.65      0.72      1142
           h       0.97      0.93      0.95      2259
           i       0.55      0.34      0.42       937
           j       0.75      0.60      0.67       579
           k       0.93      0.23      0.37       681
           l       0.36      0.06      0.11      3561
           m       0.58      0.16      0.25       796
           n       0.98      0.88      0.93      2678
           o       0.14      0.27      0.19       992
           p       0.81      0.25      0.38       568
           q       0.74      0.49      0.59       956
           r       0.99      0.89      0.94      3321
           s       0.20      0.28      0.23       735
           t       0.99      0.71      0.83      4078
           u       0.36      0.36      0.36       745
           v       0.61      0.35      0.44       825
           w       0.89      0.15      0.26       664
           x       0.93      0.31      0.46       732
           y       0.73      0.23      0.35       587
           z       0.70      0.22      0.33       709

    accuracy                           0.87    245837
   macro avg       0.81      0.74      0.75    245837
weighted avg       0.87      0.87      0.86    245837

1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 54ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 43ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 39ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 53ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 44ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 39ms/step
1/1 [==============================] - 0s 68ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 52ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 42ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 56ms/step
1/1 [==============================] - 0s 54ms/step
1/1 [==============================] - 0s 45ms/step
1/1 [==============================] - 0s 48ms/step
1/1 [==============================] - 0s 50ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 48ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 60ms/step
1/1 [==============================] - 0s 57ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 50ms/step
1/1 [==============================] - 0s 35ms/step
1/1 [==============================] - 0s 53ms/step
1/1 [==============================] - 0s 53ms/step
started training session 3
[INFO] loading existing model...
[INFO] training network...
training started at: 2022-10-25 08:22:19
Epoch 1/20
10243/10243 [==============================] - ETA: 0s - loss: 1.9181 - accuracy: 0.83912022-10-25 08:38:19.935367: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1006948352 exceeds 10% of free 
system memory.
10243/10243 [==============================] - 1133s 110ms/step - loss: 1.9181 - accuracy: 0.8391 - val_loss: 0.6702 - val_accuracy: 0.8704
Epoch 2/20
10243/10243 [==============================] - 1142s 111ms/step - loss: 1.9159 - accuracy: 0.8393 - val_loss: 0.6430 - val_accuracy: 0.8713
Epoch 3/20
10243/10243 [==============================] - 1133s 111ms/step - loss: 1.9163 - accuracy: 0.8392 - val_loss: 0.6663 - val_accuracy: 0.8715
Epoch 4/20
10243/10243 [==============================] - 1123s 110ms/step - loss: 1.9140 - accuracy: 0.8397 - val_loss: 0.6480 - val_accuracy: 0.8718
Epoch 5/20
10243/10243 [==============================] - 1132s 110ms/step - loss: 1.9152 - accuracy: 0.8390 - val_loss: 0.6382 - val_accuracy: 0.8673
Epoch 6/20
10243/10243 [==============================] - 1134s 111ms/step - loss: 1.9138 - accuracy: 0.8390 - val_loss: 0.6372 - val_accuracy: 0.8682
Epoch 7/20
10243/10243 [==============================] - 1139s 111ms/step - loss: 1.9128 - accuracy: 0.8393 - val_loss: 0.6354 - val_accuracy: 0.8691
Epoch 8/20
10243/10243 [==============================] - 1123s 110ms/step - loss: 1.9120 - accuracy: 0.8398 - val_loss: 0.6575 - val_accuracy: 0.8540
Epoch 9/20
10243/10243 [==============================] - 1133s 111ms/step - loss: 1.9122 - accuracy: 0.8394 - val_loss: 0.6379 - val_accuracy: 0.8667
Epoch 10/20
10243/10243 [==============================] - 1131s 110ms/step - loss: 1.9115 - accuracy: 0.8394 - val_loss: 0.6926 - val_accuracy: 0.8674
Epoch 11/20
10243/10243 [==============================] - 1121s 109ms/step - loss: 1.9124 - accuracy: 0.8395 - val_loss: 0.6723 - val_accuracy: 0.8693
Epoch 12/20
10243/10243 [==============================] - 1136s 111ms/step - loss: 1.9098 - accuracy: 0.8396 - val_loss: 0.6464 - val_accuracy: 0.8723
Epoch 13/20
10243/10243 [==============================] - 1129s 110ms/step - loss: 1.9119 - accuracy: 0.8394 - val_loss: 0.6825 - val_accuracy: 0.8695
Epoch 14/20
10243/10243 [==============================] - 1140s 111ms/step - loss: 1.9081 - accuracy: 0.8397 - val_loss: 0.7833 - val_accuracy: 0.8572
Epoch 15/20
10243/10243 [==============================] - 1122s 110ms/step - loss: 1.9089 - accuracy: 0.8394 - val_loss: 0.6400 - val_accuracy: 0.8707
Epoch 16/20
10243/10243 [==============================] - 1059s 103ms/step - loss: 1.9086 - accuracy: 0.8398 - val_loss: 0.6634 - val_accuracy: 0.8528
Epoch 17/20
10243/10243 [==============================] - 1045s 102ms/step - loss: 1.9111 - accuracy: 0.8394 - val_loss: 0.6380 - val_accuracy: 0.8669
Epoch 18/20
10243/10243 [==============================] - 1045s 102ms/step - loss: 1.9132 - accuracy: 0.8392 - val_loss: 0.7166 - val_accuracy: 0.8307
Epoch 19/20
10243/10243 [==============================] - 1042s 102ms/step - loss: 1.9090 - accuracy: 0.8397 - val_loss: 0.6627 - val_accuracy: 0.8708
Epoch 20/20
10243/10243 [==============================] - 1044s 102ms/step - loss: 1.9088 - accuracy: 0.8393 - val_loss: 0.6404 - val_accuracy: 0.8712
[INFO] serializing network...
[INFO] evaluating network...
2561/2561 [==============================] - 51s 20ms/step
              precision    recall  f1-score   support

           0       0.65      0.70      0.67      8298
           1       0.71      0.66      0.68      9250
           2       0.98      0.88      0.93      8239
           3       1.00      0.98      0.99      8457
           4       0.99      0.93      0.96      8072
           5       0.94      0.92      0.93      7546
           6       0.99      0.93      0.96      8222
           7       0.99      0.98      0.99      8609
           8       0.99      0.97      0.98      8154
           9       0.94      0.94      0.94      8161
           A       0.98      0.99      0.98      4326
           B       0.96      0.99      0.97      2800
           C       0.93      0.87      0.90      7190
           D       0.86      0.97      0.92      3144
           E       0.97      0.99      0.98      3395
           F       0.84      0.94      0.89      2617
           G       0.84      0.98      0.91      1928
           H       0.94      0.99      0.97      2248
           I       0.71      0.54      0.62      2907
           J       0.91      0.97      0.94      2931
           K       0.87      0.97      0.92      2119
           L       0.93      0.99      0.96      3518
           M       0.91      0.90      0.91      4681
           N       0.98      0.99      0.98      5728
           O       0.88      0.70      0.78     16802
           P       0.94      0.97      0.95      6146
           Q       0.91      0.99      0.95      2013
           R       0.97      0.99      0.98      3511
           S       0.94      0.84      0.89     14320
           T       0.94      0.99      0.96      6724
           U       0.94      0.90      0.92      8826
           V       0.81      0.87      0.84      2206
           W       0.90      0.98      0.93      3656
           X       0.85      0.98      0.91      2328
           Y       0.83      0.97      0.89      3697
           Z       0.66      0.98      0.79      2277
           a       0.96      0.89      0.93      2415
           b       0.84      0.94      0.89      1420
           c       0.35      0.57      0.43       765
           d       0.98      0.98      0.98      2510
           e       0.99      0.97      0.98      5493
           f       0.56      0.30      0.39       643
           g       0.72      0.73      0.73      1142
           h       0.97      0.96      0.97      2259
           i       0.44      0.44      0.44       937
           j       0.76      0.72      0.74       579
           k       0.90      0.55      0.68       681
           l       0.32      0.43      0.37      3561
           m       0.50      0.55      0.52       796
           n       0.98      0.93      0.95      2678
           o       0.12      0.37      0.18       992
           p       0.65      0.42      0.51       568
           q       0.62      0.60      0.61       956
           r       0.98      0.94      0.96      3321
           s       0.18      0.56      0.27       735
           t       0.98      0.88      0.93      4078
           u       0.33      0.56      0.42       745
           v       0.57      0.50      0.53       825
           w       0.84      0.42      0.56       664
           x       0.88      0.50      0.64       732
           y       0.61      0.41      0.49       587
           z       0.66      0.41      0.51       709

    accuracy                           0.87    245837
   macro avg       0.81      0.80      0.79    245837
weighted avg       0.89      0.87      0.88    245837

1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 35ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 35ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 35ms/step
1/1 [==============================] - 0s 52ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 55ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 35ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 35ms/step
1/1 [==============================] - 0s 67ms/step
1/1 [==============================] - 0s 35ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
started training session 4
[INFO] loading existing model...
[INFO] training network...
training started at: 2022-10-25 14:38:49
Epoch 1/20
10243/10243 [==============================] - 1048s 102ms/step - loss: 1.9101 - accuracy: 0.8396 - val_loss: 0.7246 - val_accuracy: 0.8636
Epoch 2/20
10243/10243 [==============================] - 1047s 102ms/step - loss: 1.9083 - accuracy: 0.8397 - val_loss: 0.6828 - val_accuracy: 0.8686
Epoch 3/20
10243/10243 [==============================] - 1045s 102ms/step - loss: 1.9104 - accuracy: 0.8395 - val_loss: 0.6372 - val_accuracy: 0.8694
Epoch 4/20
10243/10243 [==============================] - 1047s 102ms/step - loss: 1.9087 - accuracy: 0.8398 - val_loss: 0.9436 - val_accuracy: 0.8336
Epoch 5/20
10243/10243 [==============================] - 1045s 102ms/step - loss: 1.9102 - accuracy: 0.8394 - val_loss: 1.9137 - val_accuracy: 0.7204
Epoch 6/20
10243/10243 [==============================] - 1045s 102ms/step - loss: 1.9107 - accuracy: 0.8397 - val_loss: 0.7136 - val_accuracy: 0.8663
Epoch 7/20
10243/10243 [==============================] - 1045s 102ms/step - loss: 1.9076 - accuracy: 0.8398 - val_loss: 0.6511 - val_accuracy: 0.8715
Epoch 8/20
10243/10243 [==============================] - 1046s 102ms/step - loss: 1.9069 - accuracy: 0.8399 - val_loss: 0.6351 - val_accuracy: 0.8688
Epoch 9/20
10243/10243 [==============================] - 1047s 102ms/step - loss: 1.9089 - accuracy: 0.8397 - val_loss: 0.7726 - val_accuracy: 0.8581
Epoch 10/20
10243/10243 [==============================] - 1048s 102ms/step - loss: 1.9075 - accuracy: 0.8401 - val_loss: 0.6430 - val_accuracy: 0.8712
Epoch 11/20
10243/10243 [==============================] - 1046s 102ms/step - loss: 1.9072 - accuracy: 0.8398 - val_loss: 0.9490 - val_accuracy: 0.8334
Epoch 12/20
10243/10243 [==============================] - 1049s 102ms/step - loss: 1.9049 - accuracy: 0.8399 - val_loss: 0.6358 - val_accuracy: 0.8687
Epoch 13/20
10243/10243 [==============================] - 1136s 111ms/step - loss: 1.9065 - accuracy: 0.8399 - val_loss: 0.6636 - val_accuracy: 0.8712
Epoch 14/20
10243/10243 [==============================] - 1155s 113ms/step - loss: 1.9049 - accuracy: 0.8400 - val_loss: 0.6561 - val_accuracy: 0.8712
Epoch 15/20
10243/10243 [==============================] - 1151s 112ms/step - loss: 1.9048 - accuracy: 0.8404 - val_loss: 1.0718 - val_accuracy: 0.8158
Epoch 16/20
10243/10243 [==============================] - 1153s 113ms/step - loss: 1.9060 - accuracy: 0.8397 - val_loss: 0.6537 - val_accuracy: 0.8703
Epoch 17/20
10243/10243 [==============================] - 1138s 111ms/step - loss: 1.9076 - accuracy: 0.8397 - val_loss: 0.7169 - val_accuracy: 0.8649
Epoch 18/20
10243/10243 [==============================] - 1160s 113ms/step - loss: 1.9030 - accuracy: 0.8399 - val_loss: 0.7260 - val_accuracy: 0.8643
Epoch 19/20
10243/10243 [==============================] - 1147s 112ms/step - loss: 1.9053 - accuracy: 0.8398 - val_loss: 0.6444 - val_accuracy: 0.8724
Epoch 20/20
10243/10243 [==============================] - 1153s 113ms/step - loss: 1.9055 - accuracy: 0.8399 - val_loss: 0.6515 - val_accuracy: 0.8714
[INFO] serializing network...
[INFO] evaluating network...
2561/2561 [==============================] - 57s 22ms/step
              precision    recall  f1-score   support

           0       0.64      0.68      0.66      8298
           1       0.69      0.74      0.71      9250
           2       0.98      0.88      0.93      8239
           3       1.00      0.98      0.99      8457
           4       0.99      0.92      0.95      8072
           5       0.96      0.90      0.93      7546
           6       0.99      0.93      0.96      8222
           7       0.99      0.98      0.98      8609
           8       0.99      0.97      0.98      8154
           9       0.93      0.95      0.94      8161
           A       0.98      0.99      0.98      4326
           B       0.97      0.99      0.98      2800
           C       0.92      0.89      0.91      7190
           D       0.86      0.97      0.91      3144
           E       0.97      0.99      0.98      3395
           F       0.83      0.95      0.88      2617
           G       0.82      0.98      0.89      1928
           H       0.94      0.99      0.96      2248
           I       0.72      0.52      0.60      2907
           J       0.89      0.97      0.93      2931
           K       0.84      0.98      0.91      2119
           L       0.90      0.99      0.94      3518
           M       0.89      0.94      0.91      4681
           N       0.97      0.99      0.98      5728
           O       0.87      0.72      0.79     16802
           P       0.93      0.98      0.95      6146
           Q       0.91      0.99      0.94      2013
           R       0.97      0.99      0.98      3511
           S       0.93      0.87      0.90     14320
           T       0.92      0.99      0.95      6724
           U       0.93      0.92      0.92      8826
           V       0.80      0.89      0.84      2206
           W       0.88      0.98      0.93      3656
           X       0.83      0.98      0.90      2328
           Y       0.81      0.97      0.88      3697
           Z       0.65      0.98      0.78      2277
           a       0.96      0.88      0.92      2415
           b       0.86      0.94      0.90      1420
           c       0.36      0.50      0.42       765
           d       0.98      0.98      0.98      2510
           e       0.99      0.96      0.98      5493
           f       0.57      0.26      0.36       643
           g       0.75      0.72      0.73      1142
           h       0.97      0.96      0.96      2259
           i       0.46      0.41      0.43       937
           j       0.75      0.69      0.72       579
           k       0.91      0.45      0.61       681
           l       0.32      0.32      0.32      3561
           m       0.54      0.38      0.45       796
           n       0.98      0.92      0.95      2678
           o       0.12      0.35      0.18       992
           p       0.69      0.37      0.48       568
           q       0.65      0.57      0.61       956
           r       0.98      0.93      0.95      3321
           s       0.18      0.50      0.26       735
           t       0.98      0.85      0.91      4078
           u       0.35      0.48      0.40       745
           v       0.59      0.44      0.51       825
           w       0.91      0.30      0.45       664
           x       0.90      0.43      0.59       732
           y       0.63      0.35      0.45       587
           z       0.67      0.33      0.44       709

    accuracy                           0.87    245837
   macro avg       0.81      0.78      0.78    245837
weighted avg       0.88      0.87      0.87    245837

1/1 [==============================] - 0s 62ms/step
1/1 [==============================] - 0s 83ms/step
1/1 [==============================] - 0s 65ms/step
1/1 [==============================] - 0s 63ms/step
1/1 [==============================] - 0s 48ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 41ms/step
1/1 [==============================] - 0s 39ms/step
1/1 [==============================] - 0s 42ms/step
1/1 [==============================] - 0s 39ms/step
1/1 [==============================] - 0s 39ms/step
1/1 [==============================] - 0s 57ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 52ms/step
1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 57ms/step
1/1 [==============================] - 0s 56ms/step
1/1 [==============================] - 0s 49ms/step
1/1 [==============================] - 0s 56ms/step
1/1 [==============================] - 0s 44ms/step
1/1 [==============================] - 0s 40ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 62ms/step
1/1 [==============================] - 0s 60ms/step
1/1 [==============================] - 0s 53ms/step
1/1 [==============================] - 0s 61ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 61ms/step
1/1 [==============================] - 0s 56ms/step
1/1 [==============================] - 0s 84ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 48ms/step
1/1 [==============================] - 0s 59ms/step
1/1 [==============================] - 0s 55ms/step
1/1 [==============================] - 0s 63ms/step
1/1 [==============================] - 0s 66ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 55ms/step
1/1 [==============================] - 0s 59ms/step
1/1 [==============================] - 0s 50ms/step
1/1 [==============================] - 0s 40ms/step
1/1 [==============================] - 0s 43ms/step
1/1 [==============================] - 0s 38ms/step
started training session 5
[INFO] loading existing model...
[INFO] training network...
training started at: 2022-10-25 20:46:51
Epoch 1/20
10243/10243 [==============================] - 1140s 111ms/step - loss: 1.9056 - accuracy: 0.8400 - val_loss: 0.6363 - val_accuracy: 0.8671
Epoch 2/20
10243/10243 [==============================] - 1119s 109ms/step - loss: 1.8997 - accuracy: 0.8404 - val_loss: 0.9744 - val_accuracy: 0.8311
Epoch 3/20
10243/10243 [==============================] - 1141s 111ms/step - loss: 1.9070 - accuracy: 0.8396 - val_loss: 0.6418 - val_accuracy: 0.8620
Epoch 4/20
10243/10243 [==============================] - 1132s 111ms/step - loss: 1.9042 - accuracy: 0.8401 - val_loss: 0.6416 - val_accuracy: 0.8621
Epoch 5/20
10243/10243 [==============================] - 1136s 111ms/step - loss: 1.9034 - accuracy: 0.8403 - val_loss: 0.6448 - val_accuracy: 0.8715
Epoch 6/20
10243/10243 [==============================] - 1139s 111ms/step - loss: 1.9037 - accuracy: 0.8400 - val_loss: 0.6376 - val_accuracy: 0.8652
Epoch 7/20
10243/10243 [==============================] - 1133s 111ms/step - loss: 1.9031 - accuracy: 0.8399 - val_loss: 0.6441 - val_accuracy: 0.8722
Epoch 8/20
10243/10243 [==============================] - 1135s 111ms/step - loss: 1.9029 - accuracy: 0.8400 - val_loss: 0.6470 - val_accuracy: 0.8710
Epoch 9/20
10243/10243 [==============================] - 1132s 111ms/step - loss: 1.9024 - accuracy: 0.8399 - val_loss: 0.6340 - val_accuracy: 0.8677
Epoch 10/20
10243/10243 [==============================] - 1135s 111ms/step - loss: 1.8991 - accuracy: 0.8401 - val_loss: 0.6377 - val_accuracy: 0.8707
Epoch 11/20
10243/10243 [==============================] - 1139s 111ms/step - loss: 1.9018 - accuracy: 0.8404 - val_loss: 0.7961 - val_accuracy: 0.8545
Epoch 12/20
10243/10243 [==============================] - 1134s 111ms/step - loss: 1.8991 - accuracy: 0.8401 - val_loss: 0.6477 - val_accuracy: 0.8717
Epoch 13/20
10243/10243 [==============================] - 1128s 110ms/step - loss: 1.9026 - accuracy: 0.8403 - val_loss: 0.7564 - val_accuracy: 0.8592
Epoch 14/20
10243/10243 [==============================] - 1138s 111ms/step - loss: 1.9001 - accuracy: 0.8403 - val_loss: 0.7228 - val_accuracy: 0.8644
Epoch 15/20
10243/10243 [==============================] - 1136s 111ms/step - loss: 1.9030 - accuracy: 0.8400 - val_loss: 0.7143 - val_accuracy: 0.8659
Epoch 16/20
10243/10243 [==============================] - 1134s 111ms/step - loss: 1.9022 - accuracy: 0.8401 - val_loss: 0.6776 - val_accuracy: 0.8467
Epoch 17/20
10243/10243 [==============================] - 1132s 110ms/step - loss: 1.8985 - accuracy: 0.8403 - val_loss: 1.4281 - val_accuracy: 0.7773
Epoch 18/20
10243/10243 [==============================] - 1135s 111ms/step - loss: 1.8962 - accuracy: 0.8403 - val_loss: 0.6377 - val_accuracy: 0.8715
Epoch 19/20
10243/10243 [==============================] - 1137s 111ms/step - loss: 1.8993 - accuracy: 0.8402 - val_loss: 0.7196 - val_accuracy: 0.8649
Epoch 20/20
10243/10243 [==============================] - 1130s 110ms/step - loss: 1.8987 - accuracy: 0.8402 - val_loss: 0.6350 - val_accuracy: 0.8697
[INFO] serializing network...
[INFO] evaluating network...
2561/2561 [==============================] - 57s 22ms/step
              precision    recall  f1-score   support

           0       0.66      0.69      0.68      8298
           1       0.72      0.64      0.68      9250
           2       0.98      0.89      0.93      8239
           3       1.00      0.98      0.99      8457
           4       0.99      0.94      0.96      8072
           5       0.93      0.93      0.93      7546
           6       0.99      0.93      0.96      8222
           7       0.99      0.99      0.99      8609
           8       0.99      0.97      0.98      8154
           9       0.94      0.94      0.94      8161
           A       0.98      0.99      0.98      4326
           B       0.97      0.99      0.98      2800
           C       0.94      0.86      0.90      7190
           D       0.87      0.97      0.92      3144
           E       0.98      0.99      0.99      3395
           F       0.85      0.93      0.88      2617
           G       0.86      0.98      0.91      1928
           H       0.95      0.99      0.97      2248
           I       0.71      0.54      0.61      2907
           J       0.91      0.96      0.94      2931
           K       0.87      0.97      0.92      2119
           L       0.93      0.99      0.96      3518
           M       0.93      0.87      0.90      4681
           N       0.98      0.99      0.98      5728
           O       0.89      0.70      0.78     16802
           P       0.95      0.97      0.96      6146
           Q       0.93      0.99      0.96      2013
           R       0.97      0.99      0.98      3511
           S       0.95      0.81      0.87     14320
           T       0.94      0.98      0.96      6724
           U       0.94      0.88      0.91      8826
           V       0.84      0.84      0.84      2206
           W       0.91      0.97      0.94      3656
           X       0.86      0.97      0.91      2328
           Y       0.85      0.95      0.90      3697
           Z       0.69      0.97      0.81      2277
           a       0.96      0.91      0.93      2415
           b       0.83      0.94      0.89      1420
           c       0.34      0.64      0.44       765
           d       0.98      0.98      0.98      2510
           e       0.99      0.97      0.98      5493
           f       0.55      0.37      0.44       643
           g       0.72      0.74      0.73      1142
           h       0.97      0.96      0.97      2259
           i       0.37      0.47      0.42       937
           j       0.76      0.73      0.74       579
           k       0.88      0.57      0.69       681
           l       0.33      0.45      0.38      3561
           m       0.48      0.66      0.55       796
           n       0.97      0.94      0.96      2678
           o       0.11      0.43      0.18       992
           p       0.59      0.49      0.54       568
           q       0.61      0.62      0.61       956
           r       0.98      0.94      0.96      3321
           s       0.17      0.63      0.26       735
           t       0.98      0.90      0.94      4078
           u       0.32      0.62      0.42       745
           v       0.55      0.57      0.56       825
           w       0.81      0.48      0.60       664
           x       0.85      0.56      0.68       732
           y       0.59      0.48      0.53       587
           z       0.63      0.48      0.54       709

    accuracy                           0.87    245837
   macro avg       0.81      0.81      0.80    245837
weighted avg       0.89      0.87      0.88    245837

1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 59ms/step
1/1 [==============================] - 0s 53ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 49ms/step
1/1 [==============================] - 0s 39ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 49ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 45ms/step
1/1 [==============================] - 0s 50ms/step
1/1 [==============================] - 0s 39ms/step
1/1 [==============================] - 0s 67ms/step
1/1 [==============================] - 0s 40ms/step
1/1 [==============================] - 0s 58ms/step
1/1 [==============================] - 0s 56ms/step
1/1 [==============================] - 0s 53ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 53ms/step
1/1 [==============================] - 0s 39ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 60ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 35ms/step
1/1 [==============================] - 0s 35ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 58ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 37ms/step
1/1 [==============================] - 0s 54ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 53ms/step
1/1 [==============================] - 0s 35ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 55ms/step
1/1 [==============================] - 0s 44ms/step
1/1 [==============================] - 0s 53ms/step
1/1 [==============================] - 0s 50ms/step
started training session 6
[INFO] loading existing model...
[INFO] training network...
training started at: 2022-10-26 03:07:48
Epoch 1/20
10243/10243 [==============================] - 1089s 106ms/step - loss: 1.8990 - accuracy: 0.8408 - val_loss: 0.6677 - val_accuracy: 0.8698
Epoch 2/20
10243/10243 [==============================] - 1033s 101ms/step - loss: 1.8999 - accuracy: 0.8399 - val_loss: 1.1731 - val_accuracy: 0.8057
Epoch 3/20
10243/10243 [==============================] - 1039s 101ms/step - loss: 1.8999 - accuracy: 0.8404 - val_loss: 0.6999 - val_accuracy: 0.8674
Epoch 4/20
10243/10243 [==============================] - 1035s 101ms/step - loss: 1.8954 - accuracy: 0.8403 - val_loss: 0.9259 - val_accuracy: 0.8351
cy: 0.8402 - val_loss: 0.7361 - val_accuracy: 0.8633
Epoch 8/20                                                                             cy: 0.8403 - val_loss: 0.6827 - val_accuracy: 0.8691
10243/10243 [==============================] - 1038s 101ms/step - loss: 1.8967 - accuracy: 0.8403 - val_loss: 0.7490 - val_accuracy: 0.8620
Epoch 9/20
10243/10243 [==============================] - 1033s 101ms/step - loss: 1.8984 - accuracy: 0.8404 - val_loss: 0.6386 - val_accuracy: 0.8713
Epoch 10/20
10243/10243 [==============================] - 1040s 101ms/step - loss: 1.8981 - accuracy: 0.8406 - val_loss: 0.6789 - val_accuracy: 0.8696
Epoch 11/20
10243/10243 [==============================] - 1039s 101ms/step - loss: 1.8969 - accuracy: 0.8403 - val_loss: 0.6327 - val_accuracy: 0.8673
Epoch 12/20
10243/10243 [==============================] - 1037s 101ms/step - loss: 1.8962 - accuracy: 0.8403 - val_loss: 0.6426 - val_accuracy: 0.8694
Epoch 13/20
10243/10243 [==============================] - 1115s 109ms/step - loss: 1.8939 - accuracy: 0.8406 - val_loss: 1.2840 - val_accuracy: 0.7934
Epoch 14/20
 1635/10243 [===>..........................] - ETA: 13:25 - loss: 1.8882 - accuracy: 0. 1636/10243 [===>..........................] - ETA: 13:25 - loss: 1.8882 - accuracy: 0. 1637/10243 [===>.......10243/10243 [====10243/10243 [==============================] - 1162s 113ms/step - loss: 1.8958 - accuracy: 0.8401 - val_loss: 0.6371 - val_accuracy: 0.8705
Epoch 15/20
10243/10243 [==============================] - 1149s 112ms/step - loss: 1.8966 - accuracy: 0.8406 - val_loss: 0.6763 - val_accuracy: 0.8691
Epoch 16/20
10243/10243 [==============================] - 1131s 110ms/step - loss: 1.8909 - accuracy: 0.8411 - val_loss: 0.6448 - val_accuracy: 0.8609
Epoch 17/20
10243/10243 [==============================] - 1129s 110ms/step - loss: 1.8952 - accuracy: 0.8403 - val_loss: 0.6615 - val_accuracy: 0.8715
Epoch 18/20
10243/10243 [==============================] - 1144s 112ms/step - loss: 1.8940 - accuracy: 0.8408 - val_loss: 0.6376 - val_accuracy: 0.8719
Epoch 19/20
10243/10243 [==============================] - 1147s 112ms/step - loss: 1.8959 - accuracy: 0.8405 - val_loss: 0.6550 - val_accuracy: 0.8714
Epoch 20/20
10243/10243 [==============================] - 1144s 112ms/step - loss: 1.8948 - accuracy: 0.8406 - val_loss: 0.6338 - val_accuracy: 0.8674
[INFO] serializing network...
[INFO] evaluating network...
2561/2561 [==============================] - 57s 22ms/step
              precision    recall  f1-score   support

           0       0.66      0.71      0.69      8298
           1       0.74      0.59      0.66      9250
           2       0.98      0.91      0.94      8239
           3       1.00      0.99      0.99      8457
           4       0.99      0.93      0.96      8072
           5       0.93      0.93      0.93      7546
           6       0.99      0.94      0.97      8222
           7       0.99      0.99      0.99      8609
           8       0.99      0.97      0.98      8154
           9       0.95      0.92      0.93      8161
           A       0.98      0.99      0.98      4326
           B       0.97      0.99      0.98      2800
           C       0.95      0.84      0.89      7190
           D       0.88      0.97      0.92      3144
           E       0.98      0.99      0.98      3395
           F       0.86      0.89      0.88      2617
           G       0.89      0.97      0.93      1928
           H       0.95      0.99      0.97      2248
           I       0.71      0.55      0.62      2907
           J       0.93      0.96      0.94      2931
           K       0.89      0.96      0.92      2119
           L       0.94      0.98      0.96      3518
           M       0.95      0.83      0.88      4681
           N       0.98      0.99      0.98      5728
           O       0.90      0.68      0.78     16802
           P       0.95      0.96      0.95      6146
           Q       0.93      0.99      0.96      2013
           R       0.97      0.99      0.98      3511
           S       0.96      0.79      0.86     14320
           T       0.95      0.98      0.97      6724
           U       0.95      0.87      0.91      8826
           V       0.84      0.84      0.84      2206
           W       0.92      0.96      0.94      3656
           X       0.87      0.96      0.91      2328
           Y       0.86      0.94      0.90      3697
           Z       0.73      0.95      0.83      2277
           a       0.96      0.91      0.93      2415
           b       0.85      0.95      0.89      1420
           c       0.32      0.71      0.44       765
           d       0.97      0.98      0.98      2510
           e       0.99      0.97      0.98      5493
           f       0.51      0.47      0.49       643
           g       0.69      0.75      0.72      1142
           h       0.97      0.97      0.97      2259
           i       0.37      0.48      0.42       937
           j       0.74      0.77      0.75       579
           k       0.84      0.64      0.72       681
           l       0.32      0.51      0.39      3561
           m       0.44      0.77      0.56       796
           n       0.97      0.95      0.96      2678
           o       0.11      0.44      0.18       992
           p       0.56      0.56      0.56       568
           q       0.55      0.65      0.60       956
           r       0.98      0.95      0.97      3321
           s       0.16      0.70      0.26       735
           t       0.97      0.91      0.94      4078
           u       0.32      0.67      0.43       745
           v       0.53      0.59      0.56       825
           w       0.78      0.54      0.64       664
           x       0.81      0.61      0.69       732
           y       0.55      0.52      0.53       587
           z       0.60      0.53      0.56       709

    accuracy                           0.87    245837
   macro avg       0.80      0.83      0.80    245837
weighted avg       0.90      0.87      0.88    245837

1/1 [==============================] - 0s 47ms/step
1/1 [==============================] - 0s 58ms/step
1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 44ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 47ms/step
1/1 [==============================] - 0s 43ms/step
1/1 [==============================] - 0s 83ms/step
1/1 [==============================] - 0s 59ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 45ms/step
1/1 [==============================] - 0s 53ms/step
1/1 [==============================] - 0s 31ms/step
1/1 [==============================] - 0s 57ms/step
1/1 [==============================] - 0s 49ms/step
1/1 [==============================] - 0s 40ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 40ms/step
1/1 [==============================] - 0s 47ms/step
1/1 [==============================] - 0s 65ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 42ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 49ms/step
1/1 [==============================] - 0s 45ms/step
1/1 [==============================] - 0s 53ms/step
1/1 [==============================] - 0s 40ms/step
1/1 [==============================] - 0s 42ms/step
1/1 [==============================] - 0s 48ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 101ms/step
1/1 [==============================] - 0s 38ms/step
1/1 [==============================] - 0s 51ms/step
1/1 [==============================] - 0s 64ms/step
1/1 [==============================] - 0s 56ms/step
1/1 [==============================] - 0s 55ms/step
1/1 [==============================] - 0s 41ms/step
1/1 [==============================] - 0s 57ms/step
1/1 [==============================] - 0s 45ms/step
1/1 [==============================] - 0s 40ms/step
1/1 [==============================] - 0s 50ms/step
1/1 [==============================] - 0s 33ms/step
1/1 [==============================] - 0s 41ms/step
1/1 [==============================] - 0s 49ms/step
1/1 [==============================] - 0s 39ms/step
1/1 [==============================] - 0s 85ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 52ms/step
run finished at: 2022-10-26 09:09:51
total duration: 1 day, 13:11:52.456513
PS D:\Users\jmuts\Documenten\school\jaar 4\Semester 7 Artificial intelligence\personal\code\pyImageSearch>